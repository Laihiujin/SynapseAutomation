"""
æ‰¹é‡å‘å¸ƒæœåŠ¡
åŠŸèƒ½ï¼š
1. æ”¯æŒå¤šè´¦å·ã€å¤šå¹³å°æ‰¹é‡å‘å¸ƒ
2. æ™ºèƒ½ä»»åŠ¡åˆ†é…
3. å¤±è´¥è‡ªåŠ¨é‡è¯•
4. è¿›åº¦å®æ—¶åé¦ˆ
5. éªŒè¯ç è‡ªåŠ¨å¤„ç†ï¼ˆåç§»é˜Ÿåˆ—ï¼‰
"""
import uuid
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional
import json

from myUtils.exceptions import CaptchaRequiredException, AccountBlockedException
from myUtils.cookie_manager import cookie_manager
from loguru import logger
from platforms.registry import get_uploader_by_platform_code
from platforms.path_utils import resolve_cookie_file, resolve_video_file
from fastapi_app.core.timezone_utils import now_beijing_iso

class BatchPublishService:
    """æ‰¹é‡å‘å¸ƒæœåŠ¡ï¼ˆå·²è¿ç§»åˆ° Celeryï¼‰"""

    def __init__(self, task_manager=None):
        """
        åˆå§‹åŒ–æ‰¹é‡å‘å¸ƒæœåŠ¡

        Args:
            task_manager: (å·²å¼ƒç”¨) ä¿ç•™ç”¨äºå‘åå…¼å®¹ï¼Œå®é™…ä¸å†ä½¿ç”¨
        """
        # task_manager å‚æ•°ä¿ç•™ç”¨äºå‘åå…¼å®¹ï¼Œä½†ä¸å†ä½¿ç”¨
        if task_manager is not None:
            logger.warning("[BatchPublish] task_manager å‚æ•°å·²å¼ƒç”¨ï¼Œä»»åŠ¡å·²è¿ç§»åˆ° Celery")
        self.task_manager = task_manager

    async def handle_single_publish(self, data: Dict) -> Dict:
        """å¤„ç†å•ä¸ªå‘å¸ƒä»»åŠ¡"""
        platform = data.get('platform')
        account_id = data.get('account_id')
        cookie_file = data.get('cookie_file')

        # å›é€€é€»è¾‘ï¼šå¦‚æœ account_id æˆ– cookie_file ä¸ºç©ºï¼Œå°è¯•ä»æ•°ç»„è·å–
        if not account_id and data.get('accounts'):
            account_id = data['accounts'][0]
            logger.warning(f"[Publish] account_idä¸ºç©ºï¼Œä½¿ç”¨accounts[0]: {account_id}")

        if not cookie_file and data.get('account_files'):
            cookie_file = data['account_files'][0]
            logger.warning(f"[Publish] cookie_fileä¸ºç©ºï¼Œä½¿ç”¨account_files[0]: {cookie_file}")

        # å…¼å®¹ä¸¤ç§å­—æ®µåï¼švideo_path å’Œ file_path
        video_path = data.get('video_path') or data.get('file_path')
        title = data.get('title', '')
        description = data.get('description', '')  # æå– description
        tags = data.get('tags') or data.get('topics') or []
        publish_date = data.get('publish_date', 0)
        thumbnail_path = data.get('thumbnail_path', '')

        logger.info(f"[Publish] å¼€å§‹å‘å¸ƒ: {account_id} @ platform_{platform}")
        logger.info(f"   æ ‡é¢˜: {title}")
        logger.info(f"   æè¿°: {description}")
        logger.info(f"   æ ‡ç­¾: {tags}")
        logger.info(f"   è§†é¢‘: {video_path}")

        # æ£€æŸ¥å¿…éœ€å­—æ®µæ˜¯å¦ä¸º None
        if not video_path:
            error_msg = f"è§†é¢‘è·¯å¾„ä¸ºç©º: file_id={data.get('file_id')}, account_id={account_id}"
            logger.error(f"[Publish] {error_msg}")
            raise ValueError(error_msg)

        if not cookie_file:
            error_msg = f"Cookieæ–‡ä»¶è·¯å¾„ä¸ºç©º: file_id={data.get('file_id')}, account_id={account_id}"
            logger.error(f"[Publish] {error_msg}")
            logger.error(f"[Publish] ä»»åŠ¡æ•°æ®: {json.dumps(data, ensure_ascii=False)}")
            raise ValueError(error_msg)

        if not account_id:
            error_msg = f"è´¦å·IDä¸ºç©º: file_id={data.get('file_id')}, cookie_file={cookie_file}"
            logger.error(f"[Publish] {error_msg}")
            logger.error(f"[Publish] ä»»åŠ¡æ•°æ®: {json.dumps(data, ensure_ascii=False)}")
            raise ValueError(error_msg)

        try:
            if not isinstance(platform, int):
                platform = int(platform)

            uploader = get_uploader_by_platform_code(platform)

            # æŠ–éŸ³ï¼šé¿å…æŠŠ hashtags æ··è¿›æ ‡é¢˜
            upload_title = str(title or "").splitlines()[0].strip()
            if platform == 3 and "#" in upload_title:
                upload_title = upload_title.split("#", 1)[0].strip()

            # å…¼å®¹æ—§æ•°æ®ï¼šcookie_file/video_path å¯èƒ½åªæœ‰æ–‡ä»¶åï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
            cookie_file = resolve_cookie_file(cookie_file)
            video_path = resolve_video_file(video_path)

            # Fail fast with a clear error if file path is still invalid after resolution.
            try:
                if not Path(str(video_path)).exists():
                    raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            except Exception as e:
                raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}") from e

            result = await uploader.upload(
                account_file=cookie_file,
                title=upload_title,
                file_path=video_path,
                tags=tags or [],
                publish_date=publish_date if publish_date != 0 else None,
                thumbnail_path=thumbnail_path or None,
                product_link=data.get("product_link", "") or data.get("productLink", ""),
                product_title=data.get("product_title", "") or data.get("productTitle", ""),
                category=data.get("category"),
                category_id=data.get("category_id", 160),
                description=description or "",
            )

            # æ£€æŸ¥ç»“æœä¸­æ˜¯å¦åŒ…å«éªŒè¯ç æ ‡è¯†
            # æ³¨æ„ï¼špost_video_* å‡½æ•°å¯èƒ½æ²¡æœ‰è¿”å›å€¼ï¼Œå¦‚æœæ‰§è¡ŒæˆåŠŸï¼ˆæ²¡æŠ›å‡ºå¼‚å¸¸ï¼‰ï¼Œåˆ™è®¤ä¸ºæˆåŠŸ
            if result is None:
                # æ²¡æœ‰è¿”å›å€¼ï¼Œä½†æ²¡æŠ›å‡ºå¼‚å¸¸ï¼Œè®¤ä¸ºæˆåŠŸ
                logger.info(f"[Publish] å‘å¸ƒæˆåŠŸ: {account_id} @ platform_{platform}")
                cookie_manager.update_account(account_id, status='valid')
                return {
                    "success": True,
                    "account_id": account_id,
                    "platform": platform,
                    "video_url": None,
                    "published_at": now_beijing_iso()
                }

            if result and result.get('captcha_required'):
                logger.warning(f"[Publish] æ£€æµ‹åˆ°éªŒè¯ç : {account_id} @ platform_{platform}")
                # æ ‡è®°è´¦å·çŠ¶æ€ä¸ºéœ€è¦éªŒè¯
                cookie_manager.update_account(account_id, status='needs_verification')
                raise CaptchaRequiredException(
                    message=result.get('error', 'éœ€è¦äººå·¥å¤„ç†éªŒè¯ç '),
                    account_id=account_id,
                    platform=platform
                )

            # æ£€æŸ¥è´¦å·æ˜¯å¦è¢«å°ç¦
            if result and result.get('account_blocked'):
                logger.error(f"[Publish] è´¦å·è¢«å°ç¦: {account_id} @ platform_{platform}")
                cookie_manager.update_account(account_id, status='blocked')
                raise AccountBlockedException(
                    account_id=account_id,
                    platform=platform
                )

            if result and result.get('success'):
                logger.info(f"[Publish] å‘å¸ƒæˆåŠŸ: {account_id} @ platform_{platform}")
                # æ›´æ–°è´¦å·çŠ¶æ€ä¸ºæ­£å¸¸
                cookie_manager.update_account(account_id, status='valid')
                return {
                    "success": True,
                    "account_id": account_id,
                    "platform": platform,
                    "video_url": result.get('video_url'),
                    "published_at": now_beijing_iso()
                }
            else:
                error = result.get('error', 'æœªçŸ¥é”™è¯¯') if result else 'å‘å¸ƒå‡½æ•°è¿”å›ç©º'
                raise Exception(error)

        except CaptchaRequiredException:
            # éªŒè¯ç å¼‚å¸¸ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†ï¼ˆä»»åŠ¡é˜Ÿåˆ—ä¼šè‡ªåŠ¨åç§»ï¼‰
            raise
        except AccountBlockedException:
            # è´¦å·å°ç¦å¼‚å¸¸ï¼Œç›´æ¥å¤±è´¥ä¸é‡è¯•
            raise
        except Exception as e:
            logger.error(f"[Publish] å‘å¸ƒå¤±è´¥: {account_id} @ platform_{platform}")
            logger.error(f"   é”™è¯¯: {str(e)}")
            raise

    async def handle_batch_publish(self, data: Dict) -> Dict:
        """
        å¤„ç†æ‰¹é‡å‘å¸ƒä»»åŠ¡ï¼ˆä¸»ä»»åŠ¡ï¼Œä¼šæ‹†åˆ†ä¸ºå¤šä¸ªå­ä»»åŠ¡ï¼‰
        æ³¨æ„ï¼šæ­¤æ–¹æ³•ç°å·²ç”± Celery ä»»åŠ¡è°ƒç”¨ï¼Œä¸å†é€šè¿‡å†…å­˜é˜Ÿåˆ—
        """
        batch_id = data.get('batch_id', str(uuid.uuid4()))
        items = data.get('items', [])

        logger.info(f"ğŸ“¦ [BatchPublish] å¼€å§‹æ‰¹é‡å‘å¸ƒ: {batch_id}, ä»»åŠ¡æ•°: {len(items)}")

        # ä½¿ç”¨ Celery æäº¤å­ä»»åŠ¡
        from fastapi_app.tasks.publish_tasks import publish_single_task
        from fastapi_app.tasks.task_state_manager import task_state_manager

        sub_task_ids = []
        for item in items:
            # ä½¿ç”¨ Celery æäº¤ä»»åŠ¡
            result = publish_single_task.apply_async(
                kwargs={'task_data': item},
                priority=item.get('priority', 5)
            )
            sub_task_ids.append(result.id)

            # ä¿å­˜å­ä»»åŠ¡åˆ°çŠ¶æ€ç®¡ç†å™¨
            task_state_manager.create_task(
                task_id=result.id,
                task_type="publish",
                data=item,
                priority=item.get('priority', 5),
                parent_task_id=batch_id
            )

        logger.info(f"âœ… [BatchPublish] æ‰¹é‡ä»»åŠ¡å·²æäº¤: {batch_id}, å­ä»»åŠ¡æ•°: {len(sub_task_ids)}")

        return {
            "success": True,
            "batch_id": batch_id,
            "task_ids": sub_task_ids,
            "total_tasks": len(sub_task_ids)
        }

    def create_batch_publish_task(
        self,
        material_id: int,
        accounts: List[Dict],
        title: str,
        tags: List[str],
        publish_date: int = 0,
        description: str = '',
        thumbnail_path: Optional[str] = None,
        priority: int = 5
    ) -> str:
        """åˆ›å»ºæ‰¹é‡å‘å¸ƒä»»åŠ¡ï¼ˆä½¿ç”¨ Celeryï¼‰"""

        # ç”Ÿæˆæ‰¹æ¬¡ID
        batch_id = f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}"

        # å‡†å¤‡å‘å¸ƒé¡¹
        items = []
        for account in accounts:
            item = {
                'account_id': account['account_id'],
                'platform': account['platform'],
                'cookie_file': account['cookie_file'],
                'video_path': account.get('video_path'),  # ä»è¯·æ±‚ä¸­è·å–
                'title': title,
                'tags': tags,
                'publish_date': publish_date,
                'description': description,
                'thumbnail_path': thumbnail_path,
                # å¹³å°ç‰¹å®šå‚æ•°
                'productLink': account.get('productLink', ''),
                'productTitle': account.get('productTitle', ''),
                'category': account.get('category'),
                'category_id': account.get('category_id')
            }
            items.append(item)

        # ä½¿ç”¨ Celery æäº¤æ‰¹é‡ä»»åŠ¡
        from fastapi_app.tasks.publish_tasks import publish_batch_task
        from fastapi_app.tasks.task_state_manager import task_state_manager

        batch_data = {
            'batch_id': batch_id,
            'material_id': material_id,
            'items': items,
            'priority': priority
        }

        # æäº¤åˆ° Celery
        result = publish_batch_task.apply_async(
            kwargs={'batch_data': batch_data},
            priority=priority
        )

        # ä¿å­˜æ‰¹æ¬¡ä»»åŠ¡çŠ¶æ€
        task_state_manager.create_task(
            task_id=result.id,
            task_type="batch_publish",
            data=batch_data,
            priority=priority
        )

        logger.info(f"âœ… [BatchPublish] æ‰¹é‡å‘å¸ƒä»»åŠ¡å·²åˆ›å»º: {batch_id}, åŒ…å« {len(items)} ä¸ªå‘å¸ƒä»»åŠ¡")

        return batch_id

    def get_batch_status(self, batch_id: str) -> Dict:
        """è·å–æ‰¹é‡ä»»åŠ¡çŠ¶æ€ï¼ˆä» Redis æŸ¥è¯¢ï¼‰"""
        from fastapi_app.tasks.task_state_manager import task_state_manager

        # æŸ¥è¯¢æ‰¹æ¬¡ä¸»ä»»åŠ¡
        batch_status = task_state_manager.get_task_state(batch_id)
        if not batch_status:
            return {"error": "æ‰¹æ¬¡ä¸å­˜åœ¨"}

        # æŸ¥è¯¢æ‰€æœ‰å­ä»»åŠ¡
        sub_tasks = []
        task_ids = batch_status.get('result', {}).get('task_ids', [])

        for task_id in task_ids:
            task_status = task_state_manager.get_task_state(task_id)
            if task_status:
                sub_tasks.append(task_status)

        # ç»Ÿè®¡çŠ¶æ€
        stats = {
            "total": len(sub_tasks),
            "success": sum(1 for t in sub_tasks if t['status'] == 'success'),
            "failed": sum(1 for t in sub_tasks if t['status'] == 'failed'),
            "running": sum(1 for t in sub_tasks if t['status'] == 'running'),
            "pending": sum(1 for t in sub_tasks if t['status'] in ['pending', 'retry'])
        }

        return {
            "batch_id": batch_id,
            "batch_status": batch_status['status'],
            "stats": stats,
            "tasks": sub_tasks,
            "created_at": batch_status.get('created_at'),
            "started_at": batch_status.get('started_at'),
            "completed_at": batch_status.get('completed_at')
        }

# å…¨å±€å®ä¾‹
_batch_publish_service_instance = None

def get_batch_publish_service(task_manager=None) -> BatchPublishService:
    """
    è·å–æ‰¹é‡å‘å¸ƒæœåŠ¡å®ä¾‹

    Args:
        task_manager: (å·²å¼ƒç”¨) ä¿ç•™ç”¨äºå‘åå…¼å®¹
    """
    global _batch_publish_service_instance
    if _batch_publish_service_instance is None:
        _batch_publish_service_instance = BatchPublishService(task_manager)
    return _batch_publish_service_instance
