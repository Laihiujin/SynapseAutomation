"""
åŸç”Ÿ Function Calling æœåŠ¡
æ›¿ä»£ OpenManus æ¡†æ¶ï¼Œæä¾›å¯æ§çš„å•æ¬¡è°ƒç”¨æ¨¡å¼

ç‰¹ç‚¹ï¼š
- ç›´æ¥è°ƒç”¨ OpenAI å…¼å®¹æ¥å£
- å•æ¬¡å“åº”ï¼Œä¸ä¼šæ— é™å¾ªç¯æ‰§è¡Œ
- æ”¯æŒè‡ªå®šä¹‰å·¥å…·å‡½æ•°
- å®Œå…¨å¯æ§çš„æ‰§è¡Œæµç¨‹
"""
import json
import httpx
from typing import Dict, Any, List, Optional, Callable
from loguru import logger
import inspect


class Tool:
    """å·¥å…·å‡½æ•°å®šä¹‰"""
    def __init__(
        self,
        name: str,
        description: str,
        parameters: Dict[str, Any],
        function: Callable
    ):
        self.name = name
        self.description = description
        self.parameters = parameters
        self.function = function

    def to_openai_format(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸º OpenAI Function Calling æ ¼å¼"""
        return {
            "type": "function",
            "function": {
                "name": self.name,
                "description": self.description,
                "parameters": self.parameters
            }
        }

    async def execute(self, **kwargs) -> Any:
        """æ‰§è¡Œå·¥å…·å‡½æ•°"""
        # æ£€æŸ¥å‡½æ•°æ˜¯å¦æ˜¯å¼‚æ­¥çš„
        if inspect.iscoroutinefunction(self.function):
            return await self.function(**kwargs)
        else:
            return self.function(**kwargs)


class FunctionCallingService:
    """åŸç”Ÿ Function Calling æœåŠ¡"""

    def __init__(
        self,
        api_key: str,
        base_url: str = "https://api.openai.com/v1",
        model: str = "gpt-4o",
        timeout: float = 60.0
    ):
        self.api_key = api_key
        self.base_url = base_url.rstrip("/")
        self.model = model
        self.timeout = timeout
        self.tools: Dict[str, Tool] = {}

    def register_tool(self, tool: Tool):
        """æ³¨å†Œå·¥å…·å‡½æ•°"""
        self.tools[tool.name] = tool
        logger.info(f"âœ… æ³¨å†Œå·¥å…·: {tool.name}")

    def register_tools(self, tools: List[Tool]):
        """æ‰¹é‡æ³¨å†Œå·¥å…·å‡½æ•°"""
        for tool in tools:
            self.register_tool(tool)

    async def call(
        self,
        messages: List[Dict[str, str]],
        max_iterations: int = 3,
        auto_execute: bool = True
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œ Function Calling

        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆé˜²æ­¢æ— é™å¾ªç¯ï¼‰
            auto_execute: æ˜¯å¦è‡ªåŠ¨æ‰§è¡Œå·¥å…·è°ƒç”¨

        Returns:
            {
                "success": bool,
                "message": str,  # æœ€ç»ˆçš„ AI å›å¤
                "tool_calls": List[Dict],  # æ‰§è¡Œçš„å·¥å…·è°ƒç”¨è®°å½•
                "iterations": int  # å®é™…è¿­ä»£æ¬¡æ•°
            }
        """
        try:
            conversation = messages.copy()
            tool_calls_history = []
            iteration = 0
            last_assistant_content = ""

            # å‡†å¤‡å·¥å…·å®šä¹‰
            tools_definitions = [tool.to_openai_format() for tool in self.tools.values()]

            while iteration < max_iterations:
                iteration += 1
                logger.info(f"ğŸ“ Function Calling è¿­ä»£ {iteration}/{max_iterations}")

                # è°ƒç”¨ LLM
                async with httpx.AsyncClient(timeout=self.timeout) as client:
                    response = await client.post(
                        f"{self.base_url}/chat/completions",
                        headers={
                            "Authorization": f"Bearer {self.api_key}",
                            "Content-Type": "application/json"
                        },
                        json={
                            "model": self.model,
                            "messages": conversation,
                            "tools": tools_definitions,
                            "tool_choice": "auto"
                        }
                    )

                    if response.status_code != 200:
                        error_text = response.text
                        logger.error(f"âŒ LLM è°ƒç”¨å¤±è´¥: {error_text}")
                        return {
                            "success": False,
                            "message": f"LLM è°ƒç”¨å¤±è´¥: {error_text[:200]}",
                            "tool_calls": tool_calls_history,
                            "iterations": iteration
                        }

                    result = response.json()

                # è·å– AI å“åº”
                choice = result["choices"][0]
                message = choice["message"]
                finish_reason = choice.get("finish_reason")

                # å°† AI å“åº”æ·»åŠ åˆ°å¯¹è¯å†å²
                conversation.append(message)
                if message.get("content"):
                    last_assistant_content = message["content"]

                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                if finish_reason == "tool_calls" and "tool_calls" in message:
                    if not auto_execute:
                        # ä¸è‡ªåŠ¨æ‰§è¡Œï¼Œè¿”å›å·¥å…·è°ƒç”¨ä¿¡æ¯
                        return {
                            "success": True,
                            "message": message.get("content", ""),
                            "tool_calls": message["tool_calls"],
                            "iterations": iteration,
                            "pending_execution": True
                        }

                    # æ‰§è¡Œå·¥å…·è°ƒç”¨
                    tool_results = []
                    for tool_call in message["tool_calls"]:
                        tool_name = tool_call["function"]["name"]
                        tool_args_str = tool_call["function"]["arguments"]
                        tool_call_id = tool_call["id"]

                        logger.info(f"ğŸ”§ æ‰§è¡Œå·¥å…·: {tool_name}")
                        logger.debug(f"   å‚æ•°: {tool_args_str}")

                        try:
                            # è§£æå‚æ•°
                            tool_args = json.loads(tool_args_str)

                            # æŸ¥æ‰¾å·¥å…·
                            if tool_name not in self.tools:
                                error_msg = f"å·¥å…· '{tool_name}' æœªæ³¨å†Œ"
                                logger.error(f"âŒ {error_msg}")
                                tool_result = {"error": error_msg}
                            else:
                                # æ‰§è¡Œå·¥å…·
                                tool = self.tools[tool_name]
                                result_data = await tool.execute(**tool_args)
                                tool_result = result_data

                            # è®°å½•å·¥å…·è°ƒç”¨
                            tool_calls_history.append({
                                "name": tool_name,
                                "arguments": tool_args,
                                "result": tool_result
                            })

                            # æ„å»ºå·¥å…·å“åº”æ¶ˆæ¯
                            tool_results.append({
                                "tool_call_id": tool_call_id,
                                "role": "tool",
                                "name": tool_name,
                                "content": json.dumps(tool_result, ensure_ascii=False)
                            })

                        except json.JSONDecodeError as e:
                            error_msg = f"è§£æå·¥å…·å‚æ•°å¤±è´¥: {e}"
                            logger.error(f"âŒ {error_msg}")
                            tool_results.append({
                                "tool_call_id": tool_call_id,
                                "role": "tool",
                                "name": tool_name,
                                "content": json.dumps({"error": error_msg}, ensure_ascii=False)
                            })
                        except Exception as e:
                            error_msg = f"å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"
                            logger.error(f"âŒ {error_msg}")
                            tool_results.append({
                                "tool_call_id": tool_call_id,
                                "role": "tool",
                                "name": tool_name,
                                "content": json.dumps({"error": error_msg}, ensure_ascii=False)
                            })

                    # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°å¯¹è¯å†å²
                    conversation.extend(tool_results)

                    # ç»§ç»­ä¸‹ä¸€è½®å¯¹è¯ï¼ˆè®© AI æ€»ç»“ç»“æœï¼‰
                    continue

                elif finish_reason == "stop":
                    # AI å®Œæˆå“åº”ï¼Œæ²¡æœ‰æ›´å¤šå·¥å…·è°ƒç”¨
                    final_message = message.get("content", "")
                    logger.info(f"âœ… Function Calling å®Œæˆï¼Œè¿­ä»£æ¬¡æ•°: {iteration}")
                    return {
                        "success": True,
                        "message": final_message,
                        "tool_calls": tool_calls_history,
                        "iterations": iteration
                    }

                else:
                    # å…¶ä»– finish_reason
                    logger.warning(f"âš ï¸ æœªçŸ¥çš„ finish_reason: {finish_reason}")
                    return {
                        "success": False,
                        "message": message.get("content", ""),
                        "tool_calls": tool_calls_history,
                        "iterations": iteration,
                        "finish_reason": finish_reason
                    }

            # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
            logger.warning(f"âš ï¸ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° {max_iterations}")
            # ç»™æ¨¡å‹ä¸€æ¬¡â€œå¼ºåˆ¶æ”¶æŸâ€çš„æœºä¼šï¼šä¸å†å…è®¸å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¾“å‡ºå½“å‰å¯å¾—çš„ç»“æœ/ç»“è®ºã€‚
            best_effort_message = last_assistant_content or "å·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œéƒ¨åˆ†ä»»åŠ¡å¯èƒ½æœªå®Œæˆã€‚"
            try:
                summary_conversation = conversation + [{
                    "role": "user",
                    "content": (
                        "è¯·åŸºäºä»¥ä¸Šå¯¹è¯ä¸å·¥å…·è¿”å›ç»“æœï¼Œç»™å‡ºä½ èƒ½ç¡®å®šçš„ç»“è®º/è¾“å‡ºï¼›"
                        "è‹¥ä»æœ‰æœªå®Œæˆéƒ¨åˆ†ï¼Œè¯·æ˜ç¡®è¯´æ˜å¡ç‚¹å¹¶ç»™å‡ºä¸‹ä¸€æ­¥å»ºè®®ã€‚"
                        "ä¸è¦å†è°ƒç”¨ä»»ä½•å·¥å…·ã€‚"
                    )
                }]
                async with httpx.AsyncClient(timeout=self.timeout) as client:
                    response = await client.post(
                        f"{self.base_url}/chat/completions",
                        headers={
                            "Authorization": f"Bearer {self.api_key}",
                            "Content-Type": "application/json"
                        },
                        json={
                            "model": self.model,
                            "messages": summary_conversation,
                            "tool_choice": "none",
                        }
                    )
                if response.status_code != 200:
                    # å…¼å®¹éƒ¨åˆ† OpenAI-compatible å®ç°ä¸æ”¯æŒ tool_choice="none"
                    async with httpx.AsyncClient(timeout=self.timeout) as client:
                        response = await client.post(
                            f"{self.base_url}/chat/completions",
                            headers={
                                "Authorization": f"Bearer {self.api_key}",
                                "Content-Type": "application/json"
                            },
                            json={
                                "model": self.model,
                                "messages": summary_conversation,
                            }
                        )
                if response.status_code == 200:
                    result = response.json()
                    message = result["choices"][0]["message"]
                    if message.get("content"):
                        best_effort_message = message["content"]
                else:
                    logger.warning(f"âš ï¸ å¼ºåˆ¶æ”¶æŸè°ƒç”¨å¤±è´¥: {response.text[:200]}")
            except Exception as e:
                logger.warning(f"âš ï¸ å¼ºåˆ¶æ”¶æŸè°ƒç”¨å¼‚å¸¸: {e}")

            return {
                "success": True,
                "message": best_effort_message,
                "tool_calls": tool_calls_history,
                "iterations": iteration,
                "max_iterations_reached": True
            }

        except Exception as e:
            logger.error(f"âŒ Function Calling æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            return {
                "success": False,
                "message": f"æ‰§è¡Œå¤±è´¥: {str(e)}",
                "tool_calls": tool_calls_history if 'tool_calls_history' in locals() else [],
                "iterations": iteration if 'iteration' in locals() else 0
            }


# ============================================
# ä»æ•°æ®åº“åŠ è½½é…ç½®å¹¶åˆ›å»ºæœåŠ¡å®ä¾‹
# ============================================

async def get_function_calling_service() -> Optional[FunctionCallingService]:
    """
    ä»æ•°æ®åº“åŠ è½½ Function Calling é…ç½®å¹¶åˆ›å»ºæœåŠ¡å®ä¾‹

    Returns:
        FunctionCallingService å®ä¾‹ï¼Œå¦‚æœé…ç½®ä¸å­˜åœ¨åˆ™è¿”å› None
    """
    import sqlite3
    import os
    from pathlib import Path

    try:
        db_path = os.getenv("SYNAPSE_DATABASE_PATH")
        if not db_path:
            try:
                from fastapi_app.core.config import settings

                db_path = settings.DATABASE_PATH
            except Exception:
                base_dir = Path(__file__).resolve().parent.parent  # syn_backend
                db_path = str(base_dir / "db" / "database.db")
        conn = sqlite3.connect(db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        cursor.execute("""
            SELECT * FROM ai_model_configs
            WHERE service_type = 'function_calling' AND is_active = 1
        """)

        row = cursor.fetchone()
        conn.close()

        if not row:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°æ¿€æ´»çš„ Function Calling é…ç½®")
            return None

        config = dict(row)

        # åˆ›å»ºæœåŠ¡å®ä¾‹
        service = FunctionCallingService(
            api_key=config['api_key'],
            base_url=config.get('base_url') or "https://api.openai.com/v1",
            model=config.get('model_name') or "gpt-4o"
        )

        logger.info(
            f"âœ… Function Calling æœåŠ¡å·²åˆ›å»º - "
            f"Provider: {config['provider']}, Model: {service.model}"
        )

        return service

    except Exception as e:
        logger.error(f"âŒ åˆ›å»º Function Calling æœåŠ¡å¤±è´¥: {e}")
        return None
